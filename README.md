# Tinytensor (wip)

- The Huggingface's transformers versions for inference under low resource ( no GPU )

### Highlights

* Light installation footprint

* Blazing fast models ( all models use less than 10M parameters )




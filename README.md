# Tinytensor (wip)

- The Huggingface's transformers versions for inference under low resource ( no GPU )


### Highlights

* Light installation footprint

* Blazing fast models ( majority models use less than 100M parameters )

* Relies on [ONNX](https://onnxruntime.ai/) for weights inference (install size ~ 30MB) 


